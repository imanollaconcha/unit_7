{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "statewide-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the required libraries and modules that you would need.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "rough-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Read that data into Python and call the dataframe churnData.\n",
    "churndData = pd.read_csv('files_for_lab/Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "authentic-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "churndData['TotalCharges'] = pd.DataFrame(list(map(lambda x: x.replace(' ','0'),churndData['TotalCharges'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "raised-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "churndData['TotalCharges'] = pd.to_numeric(churndData['TotalCharges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "sunset-general",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are not nan values.\n",
    "churndData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "serial-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use the following features:\n",
    "features = churndData[['tenure','SeniorCitizen','MonthlyCharges','TotalCharges']]\n",
    "Y = churndData['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "overhead-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features either by using normalizer or a standard scaler.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "initial-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "strong-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model on the training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "prescribed-korea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7830777967064169"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy on the test data.\n",
    "predictions = classification.predict(X_test)\n",
    "churndData_raw = classification.score(X_test, y_test)\n",
    "churndData_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "valuable-responsibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Managing imbalance in the dataset\n",
    "churndData['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-suggestion",
   "metadata": {},
   "source": [
    "### Use the resampling strategies used in class for upsampling and downsampling to create a balance  between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "addressed-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "category_N = churndData[churndData['Churn'] == 'No']\n",
    "category_Y = churndData[churndData['Churn'] == 'Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-sullivan",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "resident-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_N_undersampled = resample(category_N, \n",
    "                                   replace=False, \n",
    "                                   n_samples = len(category_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "economic-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1869, 16)\n",
      "(1869, 16)\n"
     ]
    }
   ],
   "source": [
    "print(category_N_undersampled.shape)\n",
    "print(category_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "curious-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downsampled = pd.concat([category_N_undersampled, category_Y], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-template",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "floral-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_Y_oversampled = resample(category_Y, \n",
    "                                  replace=True, \n",
    "                                  n_samples = len(category_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "infectious-civilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5174, 16)\n",
      "(5174, 16)\n"
     ]
    }
   ],
   "source": [
    "print(category_Y_oversampled.shape)\n",
    "print(category_N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "increased-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_upsampled = pd.concat([category_N, category_Y_oversampled], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-perspective",
   "metadata": {},
   "source": [
    "### Each time fit the model and see how the accuracy of the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-bracelet",
   "metadata": {},
   "source": [
    "Downsampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "female-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_downsampled['Churn']\n",
    "data_downsampled_f = data_downsampled[['tenure','SeniorCitizen','MonthlyCharges','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "moved-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_downsampled_scaled = scaler.fit_transform(data_downsampled_f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "solved-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_downsampled_scaled,Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "coordinate-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cross-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262032085561497"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classification.predict(X_test)\n",
    "churndData_down = classification.score(X_test, y_test)\n",
    "churndData_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-facial",
   "metadata": {},
   "source": [
    "Upsampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "heated-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_upsampled['Churn']\n",
    "data_upsampled_f = data_upsampled[['tenure','SeniorCitizen','MonthlyCharges','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "outstanding-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_upsampled_scaled = scaler.fit_transform(data_upsampled_f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "inappropriate-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_upsampled_scaled,Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "changing-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fixed-praise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73057595670661"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classification.predict(X_test)\n",
    "churndData_up = classification.score(X_test, y_test)\n",
    "churndData_up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-anchor",
   "metadata": {},
   "source": [
    "### Sumary 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "valid-newman",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw data</th>\n",
       "      <th>Downsampled data</th>\n",
       "      <th>Upsampled data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.783078</td>\n",
       "      <td>0.726203</td>\n",
       "      <td>0.730576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raw data  Downsampled data  Upsampled data\n",
       "0  0.783078          0.726203        0.730576"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[churndData_raw,churndData_down,churndData_up]], \n",
    "             columns = ['Raw data','Downsampled data','Upsampled data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-victory",
   "metadata": {},
   "source": [
    "So in this case it does not make too much sense to resample the data, probably because there is not too much invalance in the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-differential",
   "metadata": {},
   "source": [
    "## 1. Apply the Random Forests algorithm but this time only by upscaling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-above",
   "metadata": {},
   "source": [
    "### With raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "certain-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = churndData['Churn']\n",
    "X = churndData[['tenure','SeniorCitizen','MonthlyCharges','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "affecting-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "anonymous-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802626908058218\n",
      "0.7806955287437899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "r_train_sc = clf.score(X_train, y_train)\n",
    "r_test_sc = clf.score(X_test, y_test)\n",
    "\n",
    "print(r_train_sc)\n",
    "print(r_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "injured-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7909083179018178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "r_cross_sc = np.mean(cross_val_scores)\n",
    "\n",
    "print(r_cross_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-vanilla",
   "metadata": {},
   "source": [
    "### With upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "opened-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_upsampled['Churn']\n",
    "X = data_upsampled[['tenure','SeniorCitizen','MonthlyCharges','TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "systematic-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "endless-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7575501328823387\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "up_train_sc = clf.score(X_train, y_train)\n",
    "up_test_sc = clf.score(X_test, y_test)\n",
    "\n",
    "print(up_train_sc)\n",
    "print(up_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "modular-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483692001238398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "up_cross_sc = np.mean(cross_val_scores)\n",
    "\n",
    "print(up_cross_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-aerospace",
   "metadata": {},
   "source": [
    "### Summary 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "neural-flush",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train score</th>\n",
       "      <th>Test score</th>\n",
       "      <th>Crosstest score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw data</th>\n",
       "      <td>0.802627</td>\n",
       "      <td>0.780696</td>\n",
       "      <td>0.790908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upsampled data</th>\n",
       "      <td>0.757550</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.748369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train score  Test score  Crosstest score\n",
       "Raw data           0.802627    0.780696         0.790908\n",
       "Upsampled data     0.757550    0.733333         0.748369"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {'Raw data':[r_train_sc, r_test_sc, r_cross_sc],\n",
    "           'Upsampled data':[up_train_sc, up_test_sc, up_cross_sc]}\n",
    "summary = pd.DataFrame(summary).T\n",
    "summary.columns = 'Train score','Test score','Crosstest score'\n",
    "summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-above",
   "metadata": {},
   "source": [
    "We can see that the scores are better with the raw data, so in this case is better not oversample the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
